{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57b9c51-1ce5-4eb7-a29c-28e2bf14f397",
   "metadata": {},
   "source": [
    "# <center>MLOps Project: Predictive Modeling for Student Final Scores based on Initial Assessments</center>\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## <center>ASSIGNMENT # 02</center>\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### <center>Ahmad Makki</center>\r\n",
    "### <center>MSDSF23M022</center>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6765e3-0d24-4682-9474-8fc9e1e5a19f",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Develop a predictive solution to anticipate students' final scores in a course based on their performance in a sequence of initial assessment activities. Given historical data featuring consistent assessment order and grading scheme, the goal is to build models that accurately forecast final scores for current iterations of the course, starting prediction after the 5th activity and extending to the final assessment.\n",
    "\n",
    "This project addresses the need for early identification of students' academic progress and facilitates targeted interventions to enhance learning outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64c9ae-5272-45a4-adea-5bc1cac1fcc5",
   "metadata": {},
   "source": [
    "## Dataset Features:\n",
    "\n",
    "| Sr#     | Roll No. | Name  | Q1   | Q2   | A1   | Q3   | Q4   | Midterm | Q5   | A2   | Q6   | Q7   | Q8   | Final | Total |\n",
    "|---------|----------|-------|------|------|------|------|------|---------|------|------|------|------|------|-------|-------|\n",
    "| Feature | Feature  | Feature | Feature | Feature | Feature | Feature | Feature | Feature    | Feature | Feature | Feature | Feature | Feature | Feature | Feature |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5037da-843d-447f-b077-a8904b5fdd52",
   "metadata": {},
   "source": [
    "# ICT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba5451-248f-4885-8dd5-8aa85ad8c6bd",
   "metadata": {},
   "source": [
    "### Data Pre Processing:\r\n",
    "In this part, pre-processes data for a machine learning task:\r\n",
    "1. It loads historical and test data from Excel files, filling missing values with zeros.\r\n",
    "2. It defines features and target variables, then calculates weighted features based on specific weights and marks.\r\n",
    "3. Finally, it computes the total score for both training and testing data using the weighted featues.\r\n",
    "es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e484337-81e1-4b42-b6e3-6b08773cecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from openpyxl import Workbook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load historical data\n",
    "data = pd.read_excel('ICT_Result_Data_Morning.xlsx')\n",
    "test_data = pd.read_excel('ICT_Result_Data_Evening.xlsx')\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "test_data.fillna(0, inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "features = ['Q1', 'Q2', 'A1', 'Q3', 'Q4', 'Midterm', 'Q5', 'A2', 'Q6', 'Q7', 'Q8', 'Final', 'Total']\n",
    "weights = [2.625, 2.625, 2, 2.625, 2.625, 35, 2.625, 2, 2.625, 2.625, 2.625, 40, 100]\n",
    "marks = [30, 49, 100, 30, 15, 35, 45, 100, 32, 24, 40, 40, 100]\n",
    "\n",
    "# Calculate weighted features for Training\n",
    "weighted_features = data[features[:-1]].multiply(weights[:-1]).divide(marks[:-1]).round()\n",
    "data['Total'] = weighted_features.sum(axis=1)\n",
    "target = data['Total']\n",
    "\n",
    "# Calculate weighted features for Testing data\n",
    "test_weighted_features = test_data[features[:-1]].multiply(weights[:-1]).divide(marks[:-1]).round()\n",
    "test_data['Total'] = test_weighted_features.sum(axis=1)\n",
    "test_target = test_data['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108f134-e8a3-4ee3-ad10-baed1d53d73d",
   "metadata": {},
   "source": [
    "### Data Modeling and Evaluation:\n",
    "- Defines a function `calculate_mse(predictions, actual)` to compute Mean Squared Error.\r\n",
    "- Initializes a Random Forest Regressor model with a specified random state.\r\n",
    "- Sets up lists to store MSE for each step of feature selection.\r\n",
    "- Iterates through each feature to predict the total score.\r\n",
    "  - Selects features up to the current iteration for training and testing.\r\n",
    "  - Splits the data into training and validation sets.\r\n",
    "  - Trains the model on the training data.\r\n",
    "  - Computes predictions for training, validation, and testing data.\r\n",
    "  - Calculates MSE for each set and stores the values.\r\n",
    "  - Prints MSE for training, validation, and testing data after each feature addition.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e96b5f-c165-45a4-aa58-f6747c85e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Models to train with their respective hyperparameters to tune\n",
    "# models = {\n",
    "#     \"Ridge\": (Ridge(), {'alpha': [0.0001, 0.001, 0.01, 0.1]}),\n",
    "#     \"Lasso\": (Lasso(), {'alpha': [0.0001, 0.001, 0.01, 0.1]}),\n",
    "#     \"MLPRegressor\": (MLPRegressor(), {'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)], 'activation': ['relu', 'tanh','logistic']}),\n",
    "#     \"Linear Regression\": (LinearRegression(), {}),\n",
    "#     \"Random Forest\": (RandomForestRegressor(), {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 10, 20]})\n",
    "# }\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": (Ridge(), {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}),\n",
    "    \"Lasso\": (Lasso(), {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}),\n",
    "    \"MLPRegressor\": (MLPRegressor(), {'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)], \n",
    "                                      'activation': ['relu', 'tanh', 'logistic'],\n",
    "                                      'solver': ['adam', 'lbfgs'],\n",
    "                                      'alpha': [0.0001, 0.001, 0.01],\n",
    "                                      'learning_rate': ['constant', 'adaptive']}),\n",
    "    \"Linear Regression\": (LinearRegression(), {}),\n",
    "    \"Random Forest\": (RandomForestRegressor(), {'n_estimators': [10, 50, 100, 200],\n",
    "                                                'max_depth': [None, 10, 20, 30],\n",
    "                                                'min_samples_split': [2, 5, 10],\n",
    "                                                'min_samples_leaf': [1, 2, 4]})\n",
    "}\n",
    "\n",
    "results = []\n",
    "mses = []\n",
    "model_names = []\n",
    "min_mse = float('inf')\n",
    "topka_model = None\n",
    "topki_pred = None\n",
    "all_abs_errors = []\n",
    "errors = []\n",
    "result = []\n",
    "\n",
    "result_df = pd.DataFrame(test_data['Roll No.'], columns=['Roll No.'])\n",
    "result_df['Actual Total'] = test_data['Total']\n",
    "errors_df = pd.DataFrame(test_data['Roll No.'], columns=['Roll No.'])\n",
    "\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    for i, feature in enumerate(features[5:-1]):  # Exclude 'Total'\n",
    "        # Train-test split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(weighted_features[[feature]], target, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get best model and predict\n",
    "        best_model = grid_search.best_estimator_\n",
    "        train_pred = best_model.predict(X_train)\n",
    "        val_pred = best_model.predict(X_val)\n",
    "        test_pred = best_model.predict(test_weighted_features[[feature]])\n",
    "\n",
    "        # Calculate MSE\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        val_mse = mean_squared_error(y_val, val_pred)\n",
    "        test_mse = mean_squared_error(test_target, test_pred)\n",
    "\n",
    "        # Store results\n",
    "        results.append({'Model': model_name, 'Feature': feature, 'Train MSE': train_mse, 'Validation MSE': val_mse, 'Test MSE': test_mse})\n",
    "\n",
    "        mses.append(test_mse)\n",
    "        model_names.append(model_name)\n",
    "\n",
    "        if test_mse < min_mse:\n",
    "            min_mse = test_mse\n",
    "            topka_model = model_name\n",
    "            topki_pred = test_pred\n",
    "\n",
    "        predicted_column_name = f'Predicted Marks {feature}'\n",
    "        result_df[predicted_column_name] = test_pred\n",
    "        abs_errors = abs(test_target - test_pred)\n",
    "        all_abs_errors.append(abs_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715936f1-a413-4ba2-8f94-89f8cb4db331",
   "metadata": {},
   "source": [
    "### Score Prediction and Error Analysis:\n",
    "This segment loops through each student to compute prediction errors:\n",
    "- It iterates over unique student IDs to isolate data for each student.\n",
    "- Extracts features and targets for training and testing.\n",
    "- Trains the model and predicts total scores for the test data.\n",
    "- Calculates absolute errors and stores statistics including average, minimum, and maximum errors.\n",
    "- Converts the error statistics into a DataFrame and saves the results to an Excel sheet for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e76a7aa-2922-4d96-8be2-34352630864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the errors dataframe for CSV output\n",
    "# errors_df['Avg Absolute Error'] = pd.concat(all_abs_errors, axis=1).mean(axis=1)\n",
    "# errors_df['Min Absolute Error'] = pd.concat(all_abs_errors, axis=1).min(axis=1)\n",
    "# errors_df['Max Absolute Error'] = pd.concat(all_abs_errors, axis=1).max(axis=1)\n",
    "\n",
    "# errors.append({'Avg Absolute Error': errors_df['Avg Absolute Error'], 'Min Absolute Error': errors_df['Min Absolute Error'], 'Max Absolute Error': errors_df['Max Absolute Error']})\n",
    "\n",
    "# Create the errors dataframe for CSV output\n",
    "errors_df['Avg Absolute Error'] = pd.concat(all_abs_errors, axis=1).mean(axis=1)\n",
    "errors_df['Min Absolute Error'] = pd.concat(all_abs_errors, axis=1).min(axis=1)\n",
    "errors_df['Max Absolute Error'] = pd.concat(all_abs_errors, axis=1).max(axis=1)\n",
    "\n",
    "errors_df = errors_df[['Avg Absolute Error', 'Min Absolute Error', 'Max Absolute Error']]\n",
    "\n",
    "# Transpose errors_df before appending\n",
    "errors.append({'Avg Absolute Error': errors_df['Avg Absolute Error'],\n",
    "                'Min Absolute Error': errors_df['Min Absolute Error'],\n",
    "                'Max Absolute Error': errors_df['Max Absolute Error']})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "errors_df = pd.DataFrame(errors)\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel('ICT_Model_Results.xlsx', index=False)\n",
    "errors_df.to_excel('ICT_Abs_Error.xlsx', index=False)\n",
    "result_df.to_excel('ICT_Marks_Pred.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a50a26-9a94-4532-bf87-280df019bd07",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "This code workflow encompasses comprehensive steps in preparing, modeling, and evaluating data for predicting student scores. Initially, it conducts data preprocessing by loading historical and test datasets, filling missing values, and computing weighted features for both training and testing data. Following this, it employs a Random Forest Regressor model to predict total scores, iterating through feature selections and evaluating model performance using Mean Squared Error (MSE). Moreover, it extends the analysis to individual students, predicting their scores and analyzing prediction errors, which are then aggregated and saved for further examination. This structured approach ensures thorough data processing, effective model training, and insightful error analysis, facilitating informed decision-making in educational assessment and intervention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a68916-0ff4-4509-a882-7f64223cb2ed",
   "metadata": {},
   "source": [
    "# CC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d65034-0f36-42dc-835c-b72848616916",
   "metadata": {},
   "source": [
    "### Data Preprocessing:\n",
    "This code segment illustrates the data preprocessing steps for a machine learning task:\r\n",
    "- It imports necessary libraries such as pandas for data manipulation and sklearn for machine learning algorithms.\r\n",
    "- Historical and test datasets are loaded from Excel files, with missing values replaced by zeros.\r\n",
    "- Features and target variables are defined based on specific weights and marks, reflecting their importance in the assessment.\r\n",
    "- Weighted features are calculated for both training and testing data to account for varying importance levels.\r\n",
    "- These weighted features are used to compute the total score, serving as the target variable for predictive modeling.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98116706-4313-4adc-bd44-993a63a4a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# Load historical data\n",
    "data = pd.read_excel('CC_Data_Morning.xlsx')\n",
    "test_data=pd.read_excel('CC_Data_Evening.xlsx')\n",
    "\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "test_data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "features = ['A1', 'Q1', 'A2', 'Q2', 'A3', 'A4', 'Q3', 'Mid', 'AWS Labs', 'Q4', 'A5', 'Q5', 'A6', 'Final']\n",
    "weights = [1, 1.5, 1, 1.5, 1, 4, 1.5, 35, 3, 1.25, 4, 1.25, 4, 40]\n",
    "marks = [10, 21, 10, 30, 100, 10, 41, 35, 10, 40, 100, 20, 100, 40]\n",
    "\n",
    "# Calculate weighted features for Training\n",
    "weighted_features = data[features].multiply(weights).divide(marks).round()\n",
    "data['Total'] = weighted_features.sum(axis=1)\n",
    "target = data['Total']\n",
    "\n",
    "# Calculate weighted features for Testing data\n",
    "test_weighted_features = test_data[features].multiply(weights).divide(marks).round()\n",
    "test_data['Total'] = test_weighted_features.sum(axis=1)\n",
    "test_target = test_data['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0b6c9-7f37-4798-848e-ffbd0387702d",
   "metadata": {},
   "source": [
    "### Model Evaluation:\n",
    "- Defines a function to calculate Mean Squared Error (MSE) for model evaluation.\n",
    "- Initializes a Random Forest Regressor model with a specified random state.\n",
    "- Iterates through features to predict the total score, splitting the data, training the model, and computing MSE for training, validation, and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252bcc5a-5016-43c0-8483-ff2fa9d38e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": (Ridge(), {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}),\n",
    "    \"Lasso\": (Lasso(), {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}),\n",
    "    \"MLPRegressor\": (MLPRegressor(), {'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)], \n",
    "                                      'activation': ['relu', 'tanh', 'logistic'],\n",
    "                                      'solver': ['adam', 'lbfgs'],\n",
    "                                      'alpha': [0.0001, 0.001, 0.01],\n",
    "                                      'learning_rate': ['constant', 'adaptive']}),\n",
    "    \"Linear Regression\": (LinearRegression(), {}),\n",
    "    \"Random Forest\": (RandomForestRegressor(), {'n_estimators': [10, 50, 100, 200],\n",
    "                                                'max_depth': [None, 10, 20, 30],\n",
    "                                                'min_samples_split': [2, 5, 10],\n",
    "                                                'min_samples_leaf': [1, 2, 4]})\n",
    "}\n",
    "\n",
    "results = []\n",
    "mses = []\n",
    "model_names = []\n",
    "min_mse = float('inf')\n",
    "topka_model = None\n",
    "topki_pred = None\n",
    "all_abs_errors = []\n",
    "errors = []\n",
    "result = []\n",
    "\n",
    "result_df = pd.DataFrame(test_data['Roll No.'], columns=['Roll No.'])\n",
    "result_df['Actual Total'] = test_data['Total']\n",
    "errors_df = pd.DataFrame(test_data['Roll No.'], columns=['Roll No.'])\n",
    "\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    for i, feature in enumerate(features[5:-1]):  # Exclude 'Total'\n",
    "        # Train-test split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(weighted_features[[feature]], target, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Grid Search for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get best model and predict\n",
    "        best_model = grid_search.best_estimator_\n",
    "        train_pred = best_model.predict(X_train)\n",
    "        val_pred = best_model.predict(X_val)\n",
    "        test_pred = best_model.predict(test_weighted_features[[feature]])\n",
    "\n",
    "        # Calculate MSE\n",
    "        train_mse = mean_squared_error(y_train, train_pred)\n",
    "        val_mse = mean_squared_error(y_val, val_pred)\n",
    "        test_mse = mean_squared_error(test_target, test_pred)\n",
    "\n",
    "        # Store results\n",
    "        results.append({'Model': model_name, 'Feature': feature, 'Train MSE': train_mse, 'Validation MSE': val_mse, 'Test MSE': test_mse})\n",
    "\n",
    "        mses.append(test_mse)\n",
    "        model_names.append(model_name)\n",
    "\n",
    "        if test_mse < min_mse:\n",
    "            min_mse = test_mse\n",
    "            topka_model = model_name\n",
    "            topki_pred = test_pred\n",
    "\n",
    "        predicted_column_name = f'Predicted Marks {feature}'\n",
    "        result_df[predicted_column_name] = test_pred\n",
    "        abs_errors = abs(test_target - test_pred)\n",
    "        all_abs_errors.append(abs_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2328f2-d4c3-4e24-b2fa-693985987eef",
   "metadata": {},
   "source": [
    "### Student Error Analysis:\n",
    "- Initializes a dictionary to store error statistics for each student including average, minimum, and maximum absolute errors.\n",
    "- Iterates through each student to calculate prediction errors using the trained model.\n",
    "- Computes absolute errors, aggregates statistics, and stores them in the error dictionary.\n",
    "- Converts the error dictionary into a DataFrame and saves the results to an Excel sheet for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d1dcd5-6336-43f9-af0f-1ad02092a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the errors dataframe for CSV output\n",
    "errors_df['Avg Absolute Error'] = pd.concat(all_abs_errors, axis=1).mean(axis=1)\n",
    "errors_df['Min Absolute Error'] = pd.concat(all_abs_errors, axis=1).min(axis=1)\n",
    "errors_df['Max Absolute Error'] = pd.concat(all_abs_errors, axis=1).max(axis=1)\n",
    "\n",
    "errors_df = errors_df[['Avg Absolute Error', 'Min Absolute Error', 'Max Absolute Error']]\n",
    "\n",
    "# Transpose errors_df before appending\n",
    "errors.append({'Avg Absolute Error': errors_df['Avg Absolute Error'],\n",
    "                'Min Absolute Error': errors_df['Min Absolute Error'],\n",
    "                'Max Absolute Error': errors_df['Max Absolute Error']})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "errors_df = pd.DataFrame(errors)\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel('CC_Model_Results.xlsx', index=False)\n",
    "errors_df.to_excel('CC_Abs_Error.xlsx', index=False)\n",
    "result_df.to_excel('CC_Marks_Pred.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f8bd6-76bd-44b8-b20a-75ccc6426a04",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The code encapsulates a thorough data processing and predictive modeling pipeline. It begins by setting up the necessary data structures and importing libraries for analysis, including pandas for data manipulation and scikit-learn for machine learning tasks. Historical and test datasets are loaded and preprocessed, with missing values replaced by zeros and features weighted based on their importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
